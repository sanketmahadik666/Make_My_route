{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Battery Analytics Lab - Data Familiarization\n",
    "\n",
    "## Phase 1: Data Ingestion & Standardization\n",
    "\n",
    "This notebook provides initial exploration and familiarization with the processed battery data.\n",
    "\n",
    "**Objectives:**\n",
    "- Explore standardized data structure and quality\n",
    "- Generate summary statistics and visualizations\n",
    "- Document data quality findings and anomalies\n",
    "- Review processing logs and metadata\n",
    "\n",
    "**Generated:** 2025-12-29\n",
    "**Author:** Battery Analytics Lab Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configuration\n",
    "config_path = \"../config/feature_schema.yaml\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")\n",
    "print(f\"‚úì Configuration loaded from: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Discovery and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover processed data files\n",
    "standardized_dir = Path(\"../data/standardized/\")\n",
    "validated_passed_dir = Path(\"../data/validated/passed/\")\n",
    "validated_failed_dir = Path(\"../data/validated/failed/\")\n",
    "\n",
    "# List available files\n",
    "standardized_files = list(standardized_dir.glob(\"*.parquet\")) if standardized_dir.exists() else []\n",
    "passed_files = list(validated_passed_dir.glob(\"*.parquet\")) if validated_passed_dir.exists() else []\n",
    "failed_files = list(validated_failed_dir.glob(\"*.parquet\")) if validated_failed_dir.exists() else []\n",
    "\n",
    "print(\"üìÅ Data File Inventory:\")\n",
    "print(f\"   Standardized files: {len(standardized_files)}\")\n",
    "print(f\"   Validation passed: {len(passed_files)}\")\n",
    "print(f\"   Validation failed: {len(failed_files)}\")\n",
    "print(f\"   Total processed: {len(standardized_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Examine Standardized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first standardized file for examination\n",
    "if standardized_files:\n",
    "    sample_file = standardized_files[0]\n",
    "    print(f\"Loading sample file: {sample_file.name}\")\n",
    "    \n",
    "    df_sample = pd.read_parquet(sample_file)\n",
    "    print(f\"\\nüìä Dataset Shape: {df_sample.shape}\")\n",
    "    print(f\"üìä Columns: {list(df_sample.columns)}\")\n",
    "    \n",
    "    # Display basic info\n",
    "    print(\"\\nüîç Data Types:\")\n",
    "    print(df_sample.dtypes)\n",
    "    \n",
    "    print(\"\\nüìà First 5 rows:\")\n",
    "    display(df_sample.head())\n",
    "    \n",
    "    print(\"\\nüìä Basic Statistics:\")\n",
    "    display(df_sample.describe())\n",
    "else:\n",
    "    print(\"‚ùå No standardized files found. Please run the data ingestion pipeline first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess data quality\n",
    "if standardized_files:\n",
    "    print(\"üîç Data Quality Assessment:\")\n",
    "    \n",
    "    # Missing values\n",
    "    missing_data = df_sample.isnull().sum()\n",
    "    missing_percentage = (missing_data / len(df_sample)) * 100\n",
    "    \n",
    "    missing_summary = pd.DataFrame({\n",
    "        'Missing_Count': missing_data,\n",
    "        'Missing_Percentage': missing_percentage\n",
    "    })\n",
    "    \n",
    "    print(\"\\nüìâ Missing Data Summary:\")\n",
    "    display(missing_summary[missing_summary['Missing_Count'] > 0])\n",
    "    \n",
    "    # Data range validation\n",
    "    value_ranges = config['raw_data_schema']['value_ranges']\n",
    "    print(\"\\nüéØ Value Range Validation:\")\n",
    "    \n",
    "    for col, range_info in value_ranges.items():\n",
    "        if col in df_sample.columns:\n",
    "            col_data = df_sample[col].dropna()\n",
    "            if len(col_data) > 0:\n",
    "                min_val, max_val = col_data.min(), col_data.max()\n",
    "                within_range = (min_val >= range_info['min']) and (max_val <= range_info['max'])\n",
    "                status = \"‚úì PASS\" if within_range else \"‚ùå FAIL\"\n",
    "                \n",
    "                print(f\"   {col}: [{min_val:.3f}, {max_val:.3f}] {range_info['unit']} \"\n",
    "                      f\"(Expected: [{range_info['min']}-{range_info['max']}]) {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "if standardized_files and len(df_sample) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Battery Data Overview', fontsize=16)\n",
    "    \n",
    "    # Voltage over time\n",
    "    if 'timestamp' in df_sample.columns and 'voltage_v' in df_sample.columns:\n",
    "        axes[0,0].plot(df_sample['timestamp'], df_sample['voltage_v'], alpha=0.7)\n",
    "        axes[0,0].set_title('Voltage vs Time')\n",
    "        axes[0,0].set_xlabel('Time (s)')\n",
    "        axes[0,0].set_ylabel('Voltage (V)')\n",
    "    \n",
    "    # Current over time\n",
    "    if 'timestamp' in df_sample.columns and 'current_a' in df_sample.columns:\n",
    "        axes[0,1].plot(df_sample['timestamp'], df_sample['current_a'], alpha=0.7, color='orange')\n",
    "        axes[0,1].set_title('Current vs Time')\n",
    "        axes[0,1].set_xlabel('Time (s)')\n",
    "        axes[0,1].set_ylabel('Current (A)')\n",
    "    \n",
    "    # Voltage distribution\n",
    "    if 'voltage_v' in df_sample.columns:\n",
    "        axes[1,0].hist(df_sample['voltage_v'].dropna(), bins=30, alpha=0.7, color='green')\n",
    "        axes[1,0].set_title('Voltage Distribution')\n",
    "        axes[1,0].set_xlabel('Voltage (V)')\n",
    "        axes[1,0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Phase type distribution\n",
    "    if 'phase_type' in df_sample.columns:\n",
    "        phase_counts = df_sample['phase_type'].value_counts()\n",
    "        axes[1,1].pie(phase_counts.values, labels=phase_counts.index, autopct='%1.1f%%')\n",
    "        axes[1,1].set_title('Phase Type Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Processing Logs Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review processing logs\n",
    "logs_dir = Path(\"../logs/\")\n",
    "logs_files = list(logs_dir.glob(\"*.log\")) if logs_dir.exists() else []\n",
    "\n",
    "print(\"üìã Processing Logs Review:\")\n",
    "print(f\"   Log files found: {len(logs_files)}\")\n",
    "\n",
    "for log_file in logs_files:\n",
    "    print(f\"\\nüìÑ {log_file.name}:\")\n",
    "    try:\n",
    "        with open(log_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"   Total lines: {len(lines)}\")\n",
    "            \n",
    "            # Show last 5 lines as summary\n",
    "            if len(lines) >= 5:\n",
    "                print(\"   Last 5 entries:\")\n",
    "                for line in lines[-5:]:\n",
    "                    print(f\"   {line.strip()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error reading log: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Metadata Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze metadata\n",
    "metadata_files = {\n",
    "    'cell_registry': Path(\"../metadata/cell_registry.csv\"),\n",
    "    'experiment_log': Path(\"../metadata/experiment_log.csv\")\n",
    "}\n",
    "\n",
    "print(\"üìä Metadata Analysis:\")\n",
    "\n",
    "for name, file_path in metadata_files.items():\n",
    "    if file_path.exists():\n",
    "        print(f\"\\nüìÑ {name}:\")\n",
    "        try:\n",
    "            df_meta = pd.read_csv(file_path)\n",
    "            print(f\"   Records: {len(df_meta)}\")\n",
    "            print(f\"   Columns: {list(df_meta.columns)}\")\n",
    "            \n",
    "            if len(df_meta) > 0:\n",
    "                display(df_meta.head())\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error reading {name}: {e}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  {name}: File not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "print(\"üìã PHASE 1 DATA FAMILIARIZATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if standardized_files:\n",
    "    print(f\"‚úì Data Files Processed: {len(standardized_files)}\")\n",
    "    print(f\"‚úì Validation Success Rate: {len(passed_files)}/{len(standardized_files)} files\")\n",
    "    print(f\"‚úì Sample Dataset Shape: {df_sample.shape}\")\n",
    "    \n",
    "    # Calculate data quality metrics\n",
    "    total_cells = df_sample.shape[0] * df_sample.shape[1]\n",
    "    missing_cells = df_sample.isnull().sum().sum()\n",
    "    completeness = (total_cells - missing_cells) / total_cells * 100\n",
    "    \n",
    "    print(f\"‚úì Data Completeness: {completeness:.1f}%\")\n",
    "    \n",
    "    print(\"\\nüìà Key Findings:\")\n",
    "    print(f\"   ‚Ä¢ Dataset contains {len(df_sample):,} data points\")\n",
    "    print(f\"   ‚Ä¢ Data spans {df_sample['timestamp'].max() - df_sample['timestamp'].min():.1f} seconds\" if 'timestamp' in df_sample.columns else \"   ‚Ä¢ Timestamp data available\")\n",
    "    print(f\"   ‚Ä¢ Voltage range: {df_sample['voltage_v'].min():.2f} - {df_sample['voltage_v'].max():.2f} V\" if 'voltage_v' in df_sample.columns else \"   ‚Ä¢ Voltage data available\")\n",
    "    \n",
    "    if 'phase_type' in df_sample.columns:\n",
    "        phase_dist = df_sample['phase_type'].value_counts()\n",
    "        print(f\"   ‚Ä¢ Phase distribution: {dict(phase_dist)}\")\n",
    "        \n",
    "    print(\"\\n‚úÖ RECOMMENDATIONS:\")\n",
    "    print(\"   ‚Ä¢ Data appears suitable for downstream analysis\")\n",
    "    print(\"   ‚Ä¢ Consider investigating any validation failures\")\n",
    "    print(\"   ‚Ä¢ Proceed to Phase 2 (Cycle Analysis)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No processed data found\")\n",
    "    print(\"üîß Next Steps:\")\n",
    "   1. Run data ingestion pipeline\")\n",
    "   2. Check processing logs for errors\")\n",
    "   3. Verify source data availability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Generated by Battery Analytics Lab - Phase 1 Data Familiarization**  \n",
    "**Date:** 2025-12-29  \n",
    "**Status:** Ready for Phase 2 (Cycle Analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}